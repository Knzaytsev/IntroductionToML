# Описание структуры работы над лабораторной

## Примерный алгоритм работы дерева решений

Работа алгоритма заключается в следующем (взято честно из статьи [2]):

      s0 = вычисляем энтропию исходного множества
      
      Если s0 == 0 значит:
            Все объекты исходного набора, принадлежат к одному классу
            Сохраняем этот класс в качестве листа дерева
            
      Если s0 != 0 значит:
            Перебираем все элементы исходного множества:
                  Для каждого элемента перебираем все его атрибуты:
                        На основе каждого атрибута генерируем предикат, который разбивает исходное множество на два подмножества
                        Рассчитываем среднее значение энтропии
                        Вычисляем ∆S
            Нас интересует предикат, с наибольшим значением ∆S
            Найденный предикат является частью дерева принятия решений, сохраняем его
            
            Разбиваем исходное множество на подмножества, согласно предикату
            Повторяем данную процедуру рекурсивно для каждого подмножества

Вычисление энтропии производится по следующей формуле [2]:

![Формула вычисления энтропии](https://github.com/Knzaytsev/IntroductionToML/raw/master/2%20lab/img/entropy.png)

∆S - это Information Gain, вычисляемый по формуле [1]:

![Формула вычисления Information Gain](https://github.com/Knzaytsev/IntroductionToML/raw/master/2%20lab/img/information%20gain.png),

где S - это энтропии, q - количество групп, N - общее число элементов


## Полезные ссылки
1.    https://habr.com/ru/company/ods/blog/322534/
2.    https://habr.com/ru/post/171759/
3.    https://edu.kpfu.ru/pluginfile.php/91556/mod_resource/content/3/Decision%20trees_1.pdf
4.    https://www.hse.ru/mirror/pubs/share/215285956
5.    https://ranalytics.github.io/data-mining/052-Binary-Decision-Trees.html
6.    https://learnmachinelearning.wikia.org/ru/wiki/Решающее_дерево_(Decision_tree)
