{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лабораторная 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABCMeta, abstractmethod\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data\\creditcard.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classificator():\n",
    "    __metaclass__ = ABCMeta\n",
    "    \n",
    "    @abstractmethod\n",
    "    def train(X, Y):\n",
    "        '''Обучить модель'''\n",
    "    \n",
    "    @abstractmethod\n",
    "    def predict(self, X, tree):\n",
    "        '''Предсказать данные'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree(Classificator):\n",
    "    \n",
    "    def train(self, X, Y, tabs=\"\", depth = 0, max_depth=None, leafValue=None):\n",
    "        entropy = self.calculate_entropy(Y)\n",
    "        node = {}\n",
    "        if entropy == 0 or depth == max_depth or len(X) == leafValue or len(X.columns) == 0:\n",
    "            p = 0\n",
    "            if len(Y.loc[Y != 1]) == 0:\n",
    "                p = 1\n",
    "            elif len(Y.loc[Y == 1]) == 0:\n",
    "                p = 0\n",
    "            else:\n",
    "                p = len(Y.loc[Y == 1]) / len(Y)\n",
    "            node['label'] = p\n",
    "            return node\n",
    "        igs = []\n",
    "        for index, row in X.iterrows():\n",
    "            inner_igs = []\n",
    "            for column in X:\n",
    "                predicate = row[column]\n",
    "                left = X[column].loc[X[column] <= predicate]\n",
    "                right = X[column].loc[X[column] > predicate]\n",
    "                Y_left = Y.loc[left.index]\n",
    "                Y_right = Y.loc[right.index]\n",
    "                groups = [[len(left), self.calculate_entropy(Y_left)], [len(right), self.calculate_entropy(Y_right)]]\n",
    "                ig = self.information_gain(Y, entropy, groups)\n",
    "                inner_igs.append(Predicate(column, ig, predicate))\n",
    "            igs.append(self.get_max_ig(inner_igs))\n",
    "\n",
    "        predicate = self.get_max_ig(igs)\n",
    "        \n",
    "        \n",
    "        X_left = X.loc[X[predicate.attribute] <= predicate.predicate].drop(predicate.attribute, axis=1)\n",
    "        X_right = X.loc[X[predicate.attribute] > predicate.predicate].drop(predicate.attribute, axis=1)\n",
    "        Y_left = Y.loc[X_left.index]\n",
    "        Y_right = Y.loc[X_right.index]\n",
    "        depth += 1\n",
    "        node['attribute'] = predicate.attribute\n",
    "        node['value'] = predicate.predicate\n",
    "        node['nodes'] = {}\n",
    "        node['nodes']['<='] = DecisionTree().train(X_left, Y_left, depth=depth, max_depth=max_depth)\n",
    "        node['nodes']['>'] = DecisionTree().train(X_right, Y_right, depth=depth, max_depth=max_depth)\n",
    "        return node\n",
    "    \n",
    "    def predict(self, X, tree):\n",
    "        X['target'] = [0 for i in range(len(X))]\n",
    "        return self.set_label(X, tree)\n",
    "    \n",
    "    def set_label(self, X, tree):\n",
    "        if 'label' in tree:\n",
    "            X.target = tree['label']\n",
    "            return X\n",
    "        left = X.loc[X[tree['attribute']] <= tree['value']]\n",
    "        X.loc[X[tree['attribute']] <= tree['value']] = self.set_label(left, tree['nodes']['<='])\n",
    "        right = X.loc[X[tree['attribute']] > tree['value']]\n",
    "        X.loc[X[tree['attribute']] > tree['value']] = self.set_label(right, tree['nodes']['>'])\n",
    "        return X\n",
    "    \n",
    "    def calculate_entropy(self, Y):\n",
    "        count = len(Y)\n",
    "        entropy = 0\n",
    "        for count_class in Y.value_counts():\n",
    "            p = count_class / count\n",
    "            entropy -= p * np.log2(p)\n",
    "        return entropy\n",
    "    \n",
    "    \n",
    "    def information_gain(self, Y, entropy0, groups):\n",
    "        N = len(Y)\n",
    "        sum_entropies = 0\n",
    "        for group in groups:\n",
    "            group\n",
    "            Ni = group[0]\n",
    "            Si = group[1]\n",
    "            sum_entropies += Ni / N * Si\n",
    "        return entropy0 - sum_entropies\n",
    "    \n",
    "    def get_max_ig(self, igs):\n",
    "        information_gain = igs[0]\n",
    "        for ig in igs:\n",
    "            if ig.ig > information_gain.ig:\n",
    "                information_gain = ig\n",
    "        return information_gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForest(Classificator):\n",
    "    tree = DecisionTree()\n",
    "    model = []\n",
    "    \n",
    "    def train(self, X, Y, N=10, max_depth=None):\n",
    "        for i in range(N):\n",
    "            Xn = X.sample(int(len(X) * 2 / 3), replace=True)\n",
    "            Yn = Y.loc[Xn.index]\n",
    "            self.model.append(self.create_tree(Xn, Yn, max_depth=max_depth))\n",
    "        return self.model\n",
    "    \n",
    "    def create_tree(self, X, Y, depth=0, max_depth=None, min_leaf=None):\n",
    "        entropy = self.tree.calculate_entropy(Y)\n",
    "        node = {}\n",
    "        if entropy == 0 or len(X.columns) == 0:\n",
    "            p = 0\n",
    "            if len(Y.loc[Y != 1]) == 0:\n",
    "                p = 1\n",
    "            elif len(Y.loc[Y == 1]) == 0:\n",
    "                p = 0\n",
    "            else:\n",
    "                p = len(Y.loc[Y == 1]) / len(Y)\n",
    "            node['label'] = p\n",
    "            return node\n",
    "        \n",
    "        X = X.sample(int(np.sqrt(len(X.columns))), axis=1)\n",
    "        igs = []\n",
    "        for index, row in X.iterrows():\n",
    "            inner_igs = []\n",
    "            for column in X:\n",
    "                predicate = row[column]\n",
    "                left = X[column].loc[X[column] <= predicate]\n",
    "                right = X[column].loc[X[column] > predicate]\n",
    "                Y_left = Y.loc[left.index]\n",
    "                Y_right = Y.loc[right.index]\n",
    "                groups = [[len(left), self.tree.calculate_entropy(Y_left)], [len(right), self.tree.calculate_entropy(Y_right)]]\n",
    "                ig = self.tree.information_gain(Y, entropy, groups)\n",
    "                inner_igs.append(Predicate(column, ig, predicate))\n",
    "            igs.append(self.tree.get_max_ig(inner_igs))\n",
    "\n",
    "        predicate = self.tree.get_max_ig(igs)\n",
    "        \n",
    "        \n",
    "        X_left = X.loc[X[predicate.attribute] <= predicate.predicate].drop(predicate.attribute, axis=1)\n",
    "        X_right = X.loc[X[predicate.attribute] > predicate.predicate].drop(predicate.attribute, axis=1)\n",
    "        Y_left = Y.loc[X_left.index]\n",
    "        Y_right = Y.loc[X_right.index]\n",
    "        depth += 1\n",
    "        node['attribute'] = predicate.attribute\n",
    "        node['value'] = predicate.predicate\n",
    "        node['nodes'] = {}\n",
    "        node['nodes']['<='] = self.create_tree(X_left, Y_left, depth=depth, max_depth=max_depth)\n",
    "        node['nodes']['>'] = self.create_tree(X_right, Y_right, depth=depth, max_depth=max_depth)\n",
    "        return node\n",
    "    \n",
    "    def predict(self, X):\n",
    "        prediction_list = []\n",
    "        res = []\n",
    "        for m in self.model:\n",
    "            prediction_list.append(self.tree.predict(X, tree=m))\n",
    "        for i in prediction_list[0].target.index:\n",
    "            label = 0\n",
    "            for t in prediction_list:\n",
    "                label += t.target[i]\n",
    "            label /= len(prediction_list)\n",
    "            res.append(label)\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradientBoosting(Classificator):\n",
    "    model = None\n",
    "    \n",
    "    def train(X, Y, M, h=None):\n",
    "        gamma = Y.mode()\n",
    "        losses = logistic_loss(Y, gamma)\n",
    "        f0 = np.argmin(np.sum(losses))\n",
    "        for t in range(M):\n",
    "            r = logistic_loss_der(X, Y)\n",
    "            h = DecisionTree().train(X, r)\n",
    "            ro = min(sum(L(y), f(x) + ro * h(x)))\n",
    "        return\n",
    "    \n",
    "    def logistic_loss(self, Y, gamma):\n",
    "        L = []\n",
    "        for y in Y[1:]:\n",
    "            L.append(np.log(1 + np.exp(-2 * y * gamma)))\n",
    "        return L\n",
    "    \n",
    "    def logistic_loss_der(self, X, Y):\n",
    "        r = []\n",
    "        for y in Y[1:]:\n",
    "            r = 2 * y / (1 + np.exp(2 * y * f(x)))\n",
    "        return -r\n",
    "    \n",
    "    def predict(self, X):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class ROC_AUC():\n",
    "    models = []\n",
    "    labels = []\n",
    "    \n",
    "    def __init__(self, models, labels):\n",
    "        self.models = models\n",
    "        self.labels = labels\n",
    "        \n",
    "    def show(self):\n",
    "        curves = []\n",
    "        for m in self.models:\n",
    "            FPR, TPR, AUC = self.roc_curve(m[0], m[1])\n",
    "            plt.plot(FPR, TPR)\n",
    "            print(AUC)\n",
    "        plt.legend(self.labels)\n",
    "        plt.show()\n",
    "    \n",
    "    def roc_curve(self, y_true, y_score):\n",
    "        y = pd.DataFrame({'true' : y_true, 'score' : y_score}).reset_index()\n",
    "        y_sorted = y.sort_values('score')\n",
    "        m = len(y_true)\n",
    "        m0 = (y_true == 0).sum()\n",
    "        m1 = (y_true == 1).sum()\n",
    "        FPR, TPR = ([0], [0])\n",
    "        AUC = 0\n",
    "        for i in range(1, m):\n",
    "            if y.true[i] == 0:\n",
    "                FPR.append(FPR[i - 1] + 1 / m0)\n",
    "                TPR.append(TPR[i - 1])\n",
    "                AUC += TPR[i] / m0\n",
    "            else:\n",
    "                FPR.append(FPR[i - 1])\n",
    "                TPR.append(TPR[i - 1] + 1 / m1)\n",
    "        return (FPR, TPR, AUC)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_tree(t, tabs='', d=''):\n",
    "    print(tabs+'predicate: ' + d)\n",
    "    if 'label' in t:\n",
    "        print(tabs+'label: ' + str(t['label']))\n",
    "    else:\n",
    "        print(tabs+'attr: ' + t['attribute'])\n",
    "        print(tabs+'val: ' + str(t['value']))\n",
    "        read_tree(t['nodes']['<='], tabs+'\\t', d='<=')\n",
    "        read_tree(t['nodes']['>'], tabs+'\\t', d='>')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Predicate:\n",
    "    attribute = \"\"\n",
    "    ig = 0\n",
    "    predicate = 0\n",
    "    \n",
    "    def __init__(self, attribute, ig, predicate):\n",
    "        self.attribute = attribute\n",
    "        self.ig = ig\n",
    "        self.predicate = predicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "492"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.loc[df.Class == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp0 = df.loc[df.Class == 1]\n",
    "temp1 = df.loc[df.Class == 0].sample(n = 500)\n",
    "temp = pd.concat([temp0, temp1]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = temp[temp.columns[:-1]]\n",
    "y = temp.Class\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adugeen\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\adugeen\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:5303: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n",
      "C:\\Users\\adugeen\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:965: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n",
      "C:\\Users\\adugeen\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:670: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "C:\\Users\\adugeen\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\adugeen\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "tree = DecisionTree()\n",
    "t = tree.train(X_train, Y_train, max_depth=3)\n",
    "predicted = tree.predict(X_test, t)\n",
    "models.append([Y_test, predicted.target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adugeen\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\adugeen\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\adugeen\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "forest = RandomForest()\n",
    "f = forest.train(X_train, Y_train, max_depth=3)\n",
    "predicted = forest.predict(X_test)\n",
    "models.append([Y_test, predicted])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4858997768309999\n",
      "0.4858997768309999\n",
      "0.4858997768309999\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAX6klEQVR4nO3df3BV5Z3H8fdXiA1o0F0IrRKQtOIIshQxIA6VWlFAuwvtjAqMFfEXRUK3o7tO2bpFdKn1V62l/GpsFbFUVNrSWLFSfzCKBSUoWgjVIqWQwV0jKqYFQgLf/ePehGu4yT1J7s9zP68ZxnvueXLu90nCl6/PeZ7nmLsjIiK577hMByAiIsmhhC4iEhJK6CIiIaGELiISEkroIiIh0TVTH9yrVy/v379/pj5eRCQnbdq06QN3L453LmMJvX///lRVVWXq40VEcpKZ/a21cxpyEREJCSV0EZGQUEIXEQmJhGPoZvYQ8K/A++4+OM55A34MXArsB6a5++sdCaahoYGamhoOHjzYkS8PlcLCQkpKSigoKMh0KCKSI4LcFF0KLACWtXL+EmBA9M+5wOLof9utpqaGoqIi+vfvT+Tfifzk7uzdu5eamhpKS0szHY6I5IiEQy7u/hLwYRtNJgLLPGIDcLKZndKRYA4ePEjPnj3zOpkDmBk9e/bU/6mISLskYwy9D7A75rgm+t4xzGy6mVWZWVVtbW3ci+V7Mm+i74OItFcy5qHHyzxx9+R19wqgAqCsrEz79opIXrjnselU1b3WfHzqccU8cP0fkv45yajQa4C+McclwJ4kXDftPv74YxYtWpTpMEQkZKrqXmN314aUf04yKvRKYJaZrSByM3Sfu7+XhOumXVNCnzlz5qfeP3z4MF26dMlQVCKSi2Kr8t1dG+jbWMAT0zen9DODTFt8DLgA6GVmNcBtQAGAuy8BVhOZsridyLTFa1IVbKrNnj2bd999l6FDh1JQUMCJJ57IKaecwubNm6muruYXv/gF8+fP59ChQ5x77rksWrSILl26sGbNGm677Tbq6+v5whe+wMMPP8yJJ56Y6e6ISAY1VeV9Gwvo21hAWdGIlH9mwoTu7lMSnHegPGkRRd3+1Faq93yS1GsOOrUHt/3bWa2ev+uuu9iyZQubN29m7dq1fPWrX2XLli2Ulpaybds2Hn/8cV555RUKCgqYOXMmy5cv59JLL2XevHk899xznHDCCdx9993cf//9zJkzJ6mxi0juSUdVHitjm3PlghEjRjTPA3/++efZtGkTw4cPB+DAgQP07t2bDRs2UF1dzahRowA4dOgQ5513XsZiFpHMiTfMkk5Zm9DbqqTT5YQTTmh+7e5cffXV/OAHP/hUm6eeeoqLL76Yxx57LN3hiUiWycQwS6ysTeiZUFRURF1dXdxzY8aMYeLEidx000307t2bDz/8kLq6OkaOHEl5eTnbt2/n9NNPZ//+/dTU1HDGGWekOXoRSZeW0xCbpOvmZ2uU0GP07NmTUaNGMXjwYLp168ZnP/vZ5nODBg1i3rx5jB07liNHjlBQUMDChQsZOXIkS5cuZcqUKdTX1wMwb948JXSREIutxGNloiqPZZF7mulXVlbmLR9wsW3bNgYOHJiReLKRvh8i2emKiqEAGanEzWyTu5fFO6ftc0VEQkIJXUQkJJTQRURCQgldRCQklNBFREJC0xZFRALI9CrQIFShtzB//nwGDhzIlVdemZLr33nnnSm5roikVuwWuJmeb94aVegtLFq0iGeeeSbQszwbGxvp2rV938I777yT7373ux0NT0TSrKkyz/Qq0CCU0GPMmDGDHTt2MGHCBKZNm8bLL7/Mjh076N69OxUVFQwZMoS5c+eyZ88edu7cSa9evXj00UeZPXs2a9eupb6+nvLycr75zW/y3nvvMWnSJD755BMaGxtZvHgxTz/9NAcOHGDo0KGcddZZLF++PNNdFpEEYpN5NlblsbI3oT8zG/73T8m95uf+BS65q9XTS5Ys4fe//z0vvvgit99+O2effTarVq3ihRdeYOrUqWzeHPmXedOmTaxbt45u3bpRUVHBSSedxMaNG6mvr2fUqFGMHTuWX//614wbN45bb72Vw4cPs3//fs4//3wWLFjQfB0RyQ3ZXpk3yd6EnmHr1q3jV7/6FQAXXnghe/fuZd++fQBMmDCBbt26AbBmzRreeustVq5cCcC+ffv4y1/+wvDhw7n22mtpaGjga1/7GkOHDs1MR0QkkEQbbuWC7E3obVTS6RBvjxuzyPOwW26r+5Of/IRx48Yd0/6ll17i6aef5qqrruKWW25h6tSpqQtYRDolWzfcao/sTegZNnr0aJYvX873vvc91q5dS69evejRo8cx7caNG8fixYu58MILKSgo4J133qFPnz588MEH9OnThxtuuIF//OMfvP7660ydOpWCggIaGhooKMiNf/FF8kmuDK20Rgm9FXPnzuWaa65hyJAhdO/enUceeSRuu+uvv56dO3cybNgw3J3i4mJWrVrF2rVruffee5ufTbps2TIApk+fzpAhQxg2bJhuiopIUmn73Cym74dI62PbyZYL0xJB2+eKSA6LXdCTSrk0Vt4aDbmISNbLhco5G6hCFxEJCSV0EZGQUEIXEQkJJXQRkZBQQhcRCQkl9ATmzp3LfffdF/fc0qVL2bNnT5ojEhGJTwm9E9pK6IcPH05zNCKS77J2Hvrdr93Nnz/8c1KveeY/n8l3RnwnYbvvf//7LFu2jL59+1JcXMw555xzTJuVK1dSVVXFlVdeSbdu3Vi/fj0DBw7k2muvZc2aNcyaNYvhw4dTXl5ObW0t3bt358EHH+TMM8+ktraWGTNmsGvXLgAeeOABRo0aldS+ikj+ydqEnimbNm1ixYoVvPHGGzQ2NjJs2LC4Cf2yyy5jwYIF3HfffZSVHV2FW1hYyLp16wAYM2YMS5YsYcCAAbz66qvMnDmTF154gW9/+9vcdNNNfOlLX2LXrl2MGzeObdu2pa2PItkiyLL+XNq+NtMCJXQzGw/8GOgC/Mzd72pxvh/wCHBytM1sd1/dmcCCVNKp8PLLL/P1r3+d7t27A5G9z9tj0qRJAPz973/nj3/8I5dffnnzufr6egCee+45qqurm9//5JNPqKuro6ioqLPhi+SU1rasjRWGJfnpkjChm1kXYCFwMVADbDSzSnevjmn238AT7r7YzAYBq4H+KYg3LZr2Pe+Ipr3Sjxw5wsknnxz36URHjhxh/fr1zQ/JEMknsVV5rmyIlSuC3BQdAWx39x3ufghYAUxs0caBps3CTwJydurH6NGj+c1vfsOBAweoq6vjqaeearVtUVERdXV1cc/16NGD0tJSnnzySSDyIIw333wTgLFjx7JgwYLmtnokneST2M22VH0nV5Ahlz7A7pjjGuDcFm3mAmvM7FvACcBF8S5kZtOB6QD9+vVrb6xpMWzYMCZNmsTQoUM57bTTOP/881ttO23aNGbMmNF8U7Sl5cuXc+ONNzJv3jwaGhqYPHkyX/ziF5k/fz7l5eUMGTKExsZGRo8ezZIlS1LZLZGsoqo8NRLuh25mlwPj3P366PFVwAh3/1ZMm5uj1/qhmZ0H/BwY7O5HWruu9kNPTN8PCaMrKiLP11VC75i29kMPUqHXAH1jjks4dkjlOmA8gLuvN7NCoBfwfvvDFZGwiDeLRbNWUifIGPpGYICZlZrZ8cBkoLJFm13AGAAzGwgUArXJDDSTysvLGTp06Kf+PPzww5kOSyTrxXs4hcbNUydhhe7ujWY2C3iWyJTEh9x9q5ndAVS5eyXwH8CDZnYTkRuk07yDz7Zz907NMkmFhQsXpv0zM/VoQJFk03h5+gSahx6dU766xXtzYl5XA51e6lhYWMjevXvp2bNn1iX1dHJ39u7dS2FhYaZDEZEcklUrRUtKSqipqaG2NjSjNR1WWFhISUlJpsMQkRySVQm9oKCA0tLSTIchIpKTtNuiiEhIKKGLiISEErqISEgooYuIhIQSuohISGTVLBcRyX3xtseV9FCFLiJJpe1xM0cVuogknZb7Z4YqdBGRkFCFLiKB6aHO2U0VuogEFm873JY0bp45qtBFpE16qHPuUIUuIm3SrJXcoQpdRBJSVZ4bVKGLiISEErqISEgooYuIhIQSuohISOimqEieS7RYSAuFcocqdJE8l2ixkKYq5g5V6CJ5SIuFwkkVukge0mKhcFKFLpKnVJWHjyp0EZGQUIUukif0aLjwU4Uukic0bh5+qtBFckCQB0skotks4acKXSQHBHmwRCKqysNPFbpIltJccWmvQBW6mY03s7fNbLuZzW6lzRVmVm1mW83sl8kNUyT/aMxb2ithhW5mXYCFwMVADbDRzCrdvTqmzQDgv4BR7v6RmfVOVcAi+URVubRHkAp9BLDd3Xe4+yFgBTCxRZsbgIXu/hGAu7+f3DBFRCSRIAm9D7A75rgm+l6sM4AzzOwVM9tgZuPjXcjMpptZlZlV1dbWdixiERGJK0hCtzjveYvjrsAA4AJgCvAzMzv5mC9yr3D3MncvKy4ubm+sIiLShiAJvQboG3NcAuyJ0+a37t7g7n8F3iaS4EVEJE2CJPSNwAAzKzWz44HJQGWLNquArwCYWS8iQzA7khmoiIi0LWFCd/dGYBbwLLANeMLdt5rZHWY2IdrsWWCvmVUDLwK3uPveVAUtIiLHCrSwyN1XA6tbvDcn5rUDN0f/iEg7tLasXxtoSXtp6b9IhrW2rF+LiaS9tPRfJAXas5mWlvVLsqhCF0mB9mympUpckkUVukiSaDMtyTRV6CJJos20JNNUoYskkapyySRV6CIiIaGELiISEkroIiIhoYQuIhISuikq0gnxpiqKZIoqdJFO0FRFySaq0EVaEWT5vhYQSTZRhS7SiiDL91WVSzZRhS5C/Gpc1bfkGlXoIsSvxlV9S65RhS55S5tpSdioQpe8pRkqEjaq0CWUNENF8pEqdAklzVCRfKQKXUJL1bfkGyV0CQ0tw5d8pyEXCQ3d5JR8pwpdcpqmHoocpQpdcpqqcpGjVKFLVks0/VBVuchRqtAlqyWafqiqXOQoVeiSdTQuLtIxqtAl62hcXKRjVKFLVlJVLtJ+qtBFREIiUEI3s/Fm9raZbTez2W20u8zM3MzKkheiiIgEkTChm1kXYCFwCTAImGJmg+K0KwL+HXg12UGKiEhiQcbQRwDb3X0HgJmtACYC1S3a/Q9wD/CfSY1Q8oL2YRHpvCBDLn2A3THHNdH3mpnZ2UBfd/9dWxcys+lmVmVmVbW1te0OVsJLM1tEOi9IhW5x3vPmk2bHAT8CpiW6kLtXABUAZWVlnqC55BnNbBHpnCAJvQboG3NcAuyJOS4CBgNrzQzgc0ClmU1w96pkBSrh0NpSfg2ziHRekCGXjcAAMys1s+OByUBl00l33+fuvdy9v7v3BzYASuYSV2tL+TXMItJ5CSt0d280s1nAs0AX4CF332pmdwBV7l7Z9hVEPk1DKyKpEWilqLuvBla3eG9OK20v6HxYIiLSXlopKiISEkroIiIhoc25JOW0aEgkPVShS8pp0ZBIeqhCl7TQzBaR1FOFLiISEkroIiIhoYQuIhISGkOXTmttf5Ymmtkikh6q0KXTWtufpYlmtoikhyp0SQrNYhHJPFXoIiIhoYQuIhISSugiIiGhhC4iEhK6KSodog23RLKPKnTpEG24JZJ9VKFLh2mqokh2UYUuIhISqtAlMI2bi2Q3VegSmMbNRbKbKnRpF42bi2QvVegiIiGhCl2O0dp2uBo3F8luqtDlGK1th6txc5Hspgpd4tJYuUjuUYUuIhISSugiIiGhIRcBtGhIJAxUoQugRUMiYaAKXZrpRqhIbgtUoZvZeDN728y2m9nsOOdvNrNqM3vLzJ43s9OSH6qIiLQlYUI3sy7AQuASYBAwxcwGtWj2BlDm7kOAlcA9yQ5URETaFqRCHwFsd/cd7n4IWAFMjG3g7i+6+/7o4QagJLlhiohIIkHG0PsAu2OOa4Bz22h/HfBMvBNmNh2YDtCvX7+AIUoytLacv4lmtojkviAVusV5z+M2NPsGUAbcG++8u1e4e5m7lxUXFwePUjqtteX8TTSzRST3BanQa4C+McclwJ6WjczsIuBW4MvuXp+c8CSZNItFJNyCVOgbgQFmVmpmxwOTgcrYBmZ2NvBTYIK7v5/8MEVEJJGECd3dG4FZwLPANuAJd99qZneY2YRos3uBE4EnzWyzmVW2cjkREUmRQAuL3H01sLrFe3NiXl+U5LgkCbScXyS/aOl/iGk5v0h+0dL/kNONUJH8oQpdRCQkVKHnkESLg1rSuLlIflGFnkMSLQ5qSePmIvlFFXoKtbeiTqSp4taYuIjEowo9hdpbUSeiiltE2qIKPYYqahHJZarQY6iiFpFclvcVerzVlKqoRSQX5X2FrtWUIhIWoazQ2zMWrqpcRMIilBV6e8bCVZWLSFiEskIH7WEiIvknlBW6iEg+UkIXEQkJJXQRkZBQQhcRCQkldBGRkFBCFxEJidBMW9QDkUUk34WmQtcSfhHJd6Gp0EGLiUQkv4WmQhcRyXdK6CIiIaGELiISEjk9hq6ZLSIiR+V0ha6ZLSIiR+V0hQ6a2SIi0iSnK3QRETlKCV1EJCQCDbmY2Xjgx0AX4GfufleL858BlgHnAHuBSe6+M7mhRuhGqIhIfAkrdDPrAiwELgEGAVPMbFCLZtcBH7n76cCPgLuTHWgT3QgVEYkvSIU+Atju7jsAzGwFMBGojmkzEZgbfb0SWGBm5u6exFib6UaoiMixgoyh9wF2xxzXRN+L28bdG4F9QM+WFzKz6WZWZWZVtbW1HQr41OOKOfW44g59rYhImAWp0C3Oey0r7yBtcPcKoAKgrKysQ9X7A9f/oSNfJiISekEq9Bqgb8xxCbCntTZm1hU4CfgwGQGKiEgwQRL6RmCAmZWa2fHAZKCyRZtK4Oro68uAF1I1fi4iIvElHHJx90YzmwU8S2Ta4kPuvtXM7gCq3L0S+DnwqJltJ1KZT05l0CIicqxA89DdfTWwusV7c2JeHwQuT25oIiLSHlopKiISEkroIiIhoYQuIhISSugiIiFhmZpdaGa1wN86+OW9gA+SGE4uUJ/zg/qcHzrT59PcPe5y+Ywl9M4wsyp3L8t0HOmkPucH9Tk/pKrPGnIREQkJJXQRkZDI1YRekekAMkB9zg/qc35ISZ9zcgxdRESOlasVuoiItKCELiISElmd0M1svJm9bWbbzWx2nPOfMbPHo+dfNbP+6Y8yuQL0+WYzqzazt8zseTM7LRNxJlOiPse0u8zM3MxyfopbkD6b2RXRn/VWM/tlumNMtgC/2/3M7EUzeyP6+31pJuJMFjN7yMzeN7MtrZw3M5sf/X68ZWbDOv2h7p6Vf4hs1fsu8HngeOBNYFCLNjOBJdHXk4HHMx13Gvr8FaB79PWN+dDnaLsi4CVgA1CW6bjT8HMeALwB/FP0uHem405DnyuAG6OvBwE7Mx13J/s8GhgGbGnl/KXAM0Se+DYSeLWzn5nNFXrzw6nd/RDQ9HDqWBOBR6KvVwJjzCze4/ByRcI+u/uL7r4/eriByBOkclmQnzPA/wD3AAfTGVyKBOnzDcBCd/8IwN3fT3OMyRakzw70iL4+iWOfjJZT3P0l2n5y20RgmUdsAE42s1M685nZnNCT9nDqHBKkz7GuI/IvfC5L2GczOxvo6+6/S2dgKRTk53wGcIaZvWJmG8xsfNqiS40gfZ4LfMPMaog8f+Fb6QktY9r79z2hQA+4yJCkPZw6hwTuj5l9AygDvpzSiFKvzT6b2XHAj4Bp6QooDYL8nLsSGXa5gMj/hb1sZoPd/eMUx5YqQfo8BVjq7j80s/OIPAVtsLsfSX14GZH0/JXNFXo+Ppw6SJ8xs4uAW4EJ7l6fpthSJVGfi4DBwFoz20lkrLEyx2+MBv3d/q27N7j7X4G3iST4XBWkz9cBTwC4+3qgkMgmVmEV6O97e2RzQs/Hh1Mn7HN0+OGnRJJ5ro+rQoI+u/s+d+/l7v3dvT+R+wYT3L0qM+EmRZDf7VVEboBjZr2IDMHsSGuUyRWkz7uAMQBmNpBIQq9Na5TpVQlMjc52GQnsc/f3OnXFTN8JTnCX+FLgHSJ3x2+NvncHkb/QEPmBPwlsB14DPp/pmNPQ5+eA/wM2R/9UZjrmVPe5Rdu15Pgsl4A/ZwPuB6qBPwGTMx1zGvo8CHiFyAyYzcDYTMfcyf4+BrwHNBCpxq8DZgAzYn7GC6Pfjz8l4/daS/9FREIim4dcRESkHZTQRURCQgldRCQklNBFREJCCV1EJCSU0EVEQkIJXUQkJP4fYyJ1ihGdkbkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "roc_auc = ROC_AUC(models, ['tree', 'forest', 'd_tree'])\n",
    "roc_auc.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=3, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "d_tree = DecisionTreeClassifier(max_depth=3)\n",
    "d_tree.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0,\n",
       "       1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "       0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0,\n",
       "       1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1,\n",
       "       0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1,\n",
       "       0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0,\n",
       "       1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0,\n",
       "       0], dtype=int64)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.append([Y_test, d_tree.predict(X_test[X_test.columns[:-1]])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
